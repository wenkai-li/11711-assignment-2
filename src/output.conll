From O
Pretraining O
Data O
to O
Language B-MethodName
Models I-MethodName
to O
Downstream O
Tasks O
: O
Tracking O
the O
Trails O
of O
Political O
Biases O
Leading O
to O
Unfair O
NLP O
Models O
Language B-MethodName
models I-MethodName
( I-MethodName
LMs I-MethodName
) I-MethodName
are O
pretrained O
on O
diverse O
data O
sources O
, O
including O
news O
, O
discussion O
forums O
, O
books O
, O
and O
online O
encyclopedias O
. O
A O
significant O
portion O
of O
this O
data O
includes O
opinions O
and O
perspectives O
which O
, O
on O
one O
hand O
, O
celebrate O
democracy O
and O
diversity O
of O
ideas O
, O
and O
on O
the O
other O
hand O
are O
inherently O
socially O
biased O
. O
Our O
work O
develops O
new O
methods O
to O
( O
1 O
) O
measure O
political O
biases O
in O
LMs B-MethodName
trained O
on O
such O
corpora O
, O
along O
social O
and O
economic O
axes O
, O
and O
( O
2 O
) O
measure O
the O
fairness O
of O
downstream O
NLP O
models O
trained O
on O
top O
of O
politically O
biased O
LMs B-MethodName
. O
We O
focus O
on O
hate B-TaskName
speech I-TaskName
and I-TaskName
misinformation I-TaskName
detection I-TaskName
, O
aiming O
to O
empirically O
quantify O
the O
effects O
of O
political O
( O
social O
, O
economic O
) O
biases O
in O
pretraining O
data O
on O
the O
fairness O
of O
high O
- O
stakes O
social O
- O
oriented O
tasks O
. O
Our O
findings O
reveal O
that O
pretrained O
LMs O
do O
have O
political O
leanings O
that O
reinforce O
the O
polarization O
present O
in O
pretraining O
corpora O
, O
propagating O
social O
biases O
into O
hate B-TaskName
speech I-TaskName
predictions I-TaskName
and O
misinformation B-TaskName
detectors I-TaskName
. O
We O
discuss O
the O
implications O
of O
our O
findings O
for O
NLP O
research O
and O
propose O
future O
directions O
to O
mitigate O
unfairness O
. O
1 O
Warning O
: O
This O
paper O
contains O
examples O
of O
hate O
speech O
. O
Introduction O
Digital O
and O
social O
media O
have O
become O
a O
major O
source O
of O
political O
news O
dissemination O
( O
Hermida O
et O
al O
. O
, O
2012 O
; O
Kümpel O
et O
al O
. O
, O
2015 O
; O
Hermida O
, O
2016 O
) O
with O
unprecedentedly O
high O
user O
engagement O
rates O
( O
Mustafaraj O
and O
Metaxas O
, O
2011 O
; O
Velasquez O
, O
2012 O
; O
Garimella O
et O
al O
. O
, O
2018 O
) O
. O
The O
volume O
of O
online O
discourse O
surrounding O
polarizing O
issues O
- O
climate O
change O
, O
gun O
control O
, O
abortion O
, O
wage O
gaps O
, O
death O
penalty O
, O
taxes O
, O
same O
- O
sex O
marriage O
, O
and O
more O
- O
has O
been O
drastically O
growing O
in O
the O
past O
decade O
( O
Valenzuela O
et O
al O
. O
, O
2012 O
; O
Rainie O
et O
al O
. O
, O
2012 O
; O
Enikolopov O
et O
al O
. O
, O
2019 O
) O
. O
While O
online O
political O
engagement O
promotes O
democratic O
values O
and O
diversity O
of O
perspectives O
, O
these O
discussions O
also O
reflect O
and O
reinforce O
societal O
biases O
- O
stereotypical O
generalizations O
about O
people O
or O
social O
groups O
( O
Devine O
, O
1989 O
; O
Bargh O
, O
1999 O
; O
Blair O
, O
2002 O
) O
. O
Such O
language O
constitutes O
a O
major O
portion O
of O
large B-MethodName
language I-MethodName
models I-MethodName
' I-MethodName
( I-MethodName
LMs I-MethodName
) I-MethodName
pretraining O
data O
, O
propagating O
biases O
into O
downstream O
models O
. O
Hundreds O
of O
studies O
have O
highlighted O
ethical O
issues O
in O
NLP O
models O
( O
Blodgett O
et O
al O
. O
, O
2020a O
; O
Field O
et O
al O
. O
, O
2021 O
; O
Kumar O
et O
al O
. O
, O
2022 O
) O
and O
designed O
synthetic O
datasets O
( O
Nangia O
et O
al O
. O
, O
2020 O
; O
Nadeem O
et O
al O
. O
, O
2021 O
) O
or O
controlled O
experiments O
to O
measure O
how O
biases O
in O
language O
are O
encoded O
in O
learned O
representations O
( O
Sun O
et O
al O
. O
, O
2019 O
) O
, O
and O
how O
annotator O
errors O
in O
training O
data O
are O
liable O
to O
increase O
unfairness O
of O
NLP O
models O
( O
Sap O
et O
al O
. O
, O
2019 O
) O
. O
However O
, O
the O
language O
of O
polarizing O
political O
issues O
is O
particularly O
complex O
( O
Demszky O
et O
al O
. O
, O
2019 O
) O
, O
and O
social O
biases O
hidden O
in O
language O
can O
rarely O
be O
reduced O
to O
pre O
- O
specified O
stereotypical O
associations O
( O
Joseph O
and O
Morgan O
, O
2020 O
) O
. O
To O
the O
best O
of O
our O
knowledge O
, O
no O
prior O
work O
has O
shown O
how O
to O
analyze O
the O
effects O
of O
naturally O
occurring O
media O
biases O
in O
pretraining O
data O
on O
language O
models O
, O
and O
subsequently O
on O
downstream O
tasks O
, O
and O
how O
it O
affects O
the O
fairness O
towards O
diverse O
social O
groups O
. O
Our O
study O
aims O
to O
fill O
this O
gap O
. O
As O
a O
case O
study O
, O
we O
focus O
on O
the O
effects O
of O
media O
biases O
in O
pretraining O
data O
on O
the O
fairness O
of O
hate B-TaskName
speech I-TaskName
detection I-TaskName
with O
respect O
to O
diverse O
social O
attributes O
, O
such O
as O
gender O
, O
race O
, O
ethnicity O
, O
religion O
, O
and O
sexual O
orientation O
, O
and O
of O
misinformation O
detection O
with O
respect O
to O
partisan O
leanings O
. O
We O
investigate O
how O
media O
biases O
in O
the O
pretraining O
data O
propagate O
into O
LMs O
and O
ultimately O
affect O
downstream O
tasks O
, O
because O
discussions O
about O
polarizing O
social O
and O
economic O
issues O
are O
abundant O
in O
pretraining O
data O
sourced O
from O
news O
, O
forums O
, O
books O
, O
and O
online O
encyclopedias O
, O
and O
this O
language O
inevitably O
perpetuates O
social O
stereotypes O
. O
We O
choose O
hate B-TaskName
speech I-TaskName
and I-TaskName
misinformation I-TaskName
classification I-TaskName
because O
these O
are O
social O
- O
oriented O
tasks O
in O
which O
unfair O
predictions O
can O
be O
especially O
harmful O
( O
Duggan O
, O
2017 O
; O
League O
, O
2019League O
, O
, O
2021 O
. O
To O
this O
end O
, O
grounded O
in O
political B-MethodName
spectrum I-MethodName
theories I-MethodName
( O
Eysenck O
, O
1957 O
; O
Rokeach O
, O
1973 O
; O
Gindler O
, O
2021 O
) O
and O
the O
political B-MethodName
compass I-MethodName
test I-MethodName
, O
2 O
we O
propose O
to O
empirically O
quantify O
the O
political B-TaskName
leaning I-TaskName
of O
pretrained O
LMs B-MethodName
( O
§ O
2 O
) O
. O
We O
then O
further O
pretrain O
language B-MethodName
models I-MethodName
on O
different O
partisan O
corpora O
to O
investigate O
whether O
LMs B-MethodName
pick O
up O
political O
biases O
from O
training O
data O
. O
Finally O
, O
we O
train O
classifiers B-MethodName
on O
top O
of O
LMs B-MethodName
with O
varying O
political O
leanings O
and O
evaluate O
their O
performance O
on O
hate B-DatasetName
speech I-DatasetName
instances I-DatasetName
targeting I-DatasetName
different I-DatasetName
identity I-DatasetName
groups I-DatasetName
( O
Yoder O
et O
al O
. O
, O
2022 O
) O
, O
and O
on O
misinformation B-DatasetName
detection I-DatasetName
with I-DatasetName
different I-DatasetName
agendas I-DatasetName
( O
Wang O
, O
2017 O
) O
. O
In O
this O
way O
, O
we O
investigate O
the O
propagation O
of O
political O
bias O
through O
the O
entire O
pipeline O
from O
pretraining O
data O
to O
language B-MethodName
models I-MethodName
to O
downstream O
tasks O
. O
Our O
experiments O
across O
several O
data O
domains O
, O
partisan O
news O
datasets O
, O
and O
LM O
architectures O
( O
§ O
3 O
) O
demonstrate O
that O
different O
pretrained O
LMs B-MethodName
do O
have O
different O
underlying O
political O
leanings O
, O
reinforcing O
the O
political O
polarization O
present O
in O
pretraining O
corpora O
( O
§ O
4.1 O
) O
. O
Further O
, O
while O
the O
overall O
performance O
of O
hate B-TaskName
speech I-TaskName
and I-TaskName
misinformation I-TaskName
detectors I-TaskName
remains O
consistent O
across O
such O
politically O
- O
biased O
LMs B-MethodName
, O
these O
models O
exhibit O
significantly O
different O
behaviors O
against O
different O
identity O
groups O
and O
partisan O
media O
sources O
. O
( O
§ O
4.2 O
) O
. O
The O
main O
contributions O
of O
this O
paper O
are O
novel O
methods O
to O
quantify O
political O
biases O
in O
LMs B-MethodName
, O
and O
findings O
that O
shed O
new O
light O
on O
how O
ideological O
polarization O
in O
pretraining O
corpora O
propagates O
biases O
into O
language O
models O
, O
and O
subsequently O
into O
social O
- O
oriented O
downstream O
tasks O
. O
In O
§ O
5 O
, O
we O
discuss O
implications O
of O
our O
findings O
for O
NLP O
research O
, O
that O
no O
language O
model O
can O
be O
entirely O
free O
from O
social O
biases O
, O
and O
propose O
future O
directions O
to O
mitigate O
unfairness O
. O
Methodology O
We O
propose O
a O
two O
- O
step O
methodology O
to O
establish O
the O
effect O
of O
political O
biases O
in O
pretraining O
corpora O
on O
the O
fairness O
of O
downstream O
tasks O
: O
( O
1 O
) O
we O
develop O
a O
framework O
, O
grounded O
in O
political O
science O
literature O
, O
to O
measure O
the O
inherent O
political O
leanings O
of O
pretrained O
language B-MethodName
models I-MethodName
, O
and O
( O
2 O
) O
then O
investi O
- O
gate O
how O
the O
political O
leanings O
of O
LMs O
affect O
their O
performance O
in O
downstream O
social O
- O
oriented O
tasks O
. O
Measuring O
the O
Political O
Leanings O
of O
LMs B-MethodName
While O
prior O
works O
provided O
analyses O
of O
political O
leanings O
in O
LMs B-MethodName
( O
Jiang O
et O
al O
. O
, O
2022a O
; O
Argyle O
et O
al O
. O
, O
2022 O
) O
, O
they O
primarily O
focused O
on O
political O
individuals O
, O
rather O
than O
the O
timeless O
ideological O
issues O
grounded O
in O
political O
science O
literature O
. O
In O
contrast O
, O
our O
method O
is O
grounded O
in O
political B-MethodName
spectrum I-MethodName
theories I-MethodName
( O
Eysenck O
, O
1957 O
; O
Rokeach O
, O
1973 O
; O
Gindler O
, O
2021 O
) O
that O
provide O
more O
nuanced O
perspective O
than O
the O
commonly O
used O
left O
vs. O
right O
distinction O
( O
Bobbio O
, O
1996 O
; O
Mair O
, O
2007 O
; O
Corballis O
and O
Beale O
, O
2020 O
) O
by O
assessing O
political O
positions O
on O
two O
axes O
: O
social O
values O
( O
ranging O
from O
liberal O
to O
conservative O
) O
and O
economic O
values O
( O
ranging O
from O
left O
to O
right O
) O
. O
The O
widely O
adopted O
political B-MethodName
compass I-MethodName
test I-MethodName
, O
2 O
which O
is O
based O
on O
these O
theories O
, O
measures O
individuals O
' O
leaning O
on O
a O
two O
- O
dimensional O
space O
by O
analyzing O
their O
responses O
to O
62 O
political O
statements O
. O
3 O
Participants O
indicate O
their O
level O
of O
agreement O
or O
disagreement O
with O
each O
statement O
, O
and O
their O
responses O
are O
used O
to O
calculate O
their O
social O
and O
economic O
scores O
through O
weighted O
summation O
. O
Formally O
, O
the O
political B-MethodName
compass I-MethodName
test I-MethodName
maps O
a O
set O
of O
answers O
indicating O
agreement O
level O
{ O
STRONG O
DISAGREE O
, O
DISAGREE O
, O
AGREE O
, O
STRONG O
AGREE O
} O
62 O
to O
twodimensional O
point O
( O
s O
soc O
, O
s O
eco O
) O
, O
where O
the O
social O
score O
s O
soc O
and O
economic O
score O
s O
eco O
range O
from O
[ O
−10 O
, O
10 O
] O
. O
We O
employ O
this O
test O
as O
a O
tool O
to O
measure O
the O
political O
leanings O
of O
pretrained O
language B-MethodName
models I-MethodName
. O
We O
probe O
a O
diverse O
set O
of O
LMs B-MethodName
to O
measure O
their O
alignment O
with O
specific O
political O
statements O
, O
including O
encoder B-MethodName
and O
language B-MethodName
generation I-MethodName
models I-MethodName
( I-MethodName
decoder I-MethodName
and I-MethodName
autoregressive I-MethodName
) I-MethodName
. O
For O
encoderonly O
LMs B-MethodName
, O
we O
use O
mask B-MethodName
filling O
with O
prompts O
derived O
from O
the O
political O
statements O
. O
We O
construct O
the O
following O
prompt O
: O
" O
Please O
respond O
to O
the O
following O
statement O
: O
[ O
STATEMENT O
] O
I O
< O
MASK O
> O
with O
this O
statement O
. O
" O
Then O
, O
pretrained O
LMs B-MethodName
fill O
the O
mask O
and O
return O
10 B-HyperparameterValue
highest B-HyperparameterName
probability I-HyperparameterName
tokens I-HyperparameterName
. O
By O
comparing O
the O
aggregated O
probability O
of O
pre O
- O
defined O
positive O
( O
agree O
, O
support O
, O
endorse O
, O
etc O
. O
) O
We O
probe O
language B-MethodName
generation I-MethodName
models I-MethodName
by O
conducting O
text B-TaskName
generation I-TaskName
based O
on O
the O
following O
prompt O
: O
" O
Please O
respond O
to O
the O
following O
statement O
: O
[ O
STATEMENT O
] O
\n O
Your O
response O
: O
" O
. O
We O
then O
use O
an O
off O
- O
the O
- O
shelf O
stance O
detector O
to O
determine O
whether O
the O
generated O
response O
agrees O
or O
disagrees O
with O
the O
given O
statement O
. O
We O
use O
10 O
random O
seeds O
for O
prompted O
generation O
, O
filter O
low O
- O
confidence O
responses O
using O
the O
stance B-MethodName
detector I-MethodName
, O
and O
average O
the O
stance O
detection O
scores O
for O
a O
more O
reliable O
evaluation O
. O
5 O
Using O
this O
framework O
, O
we O
aim O
to O
systematically O
evaluate O
the O
effect O
of O
polarization O
in O
pretraining O
data O
on O
the O
political O
bias O
of O
LMs B-MethodName
. O
We O
thus O
train O
multiple O
partisan O
LMs B-MethodName
through O
continued O
pretraining O
of O
existing O
LMs B-MethodName
on O
data O
from O
various O
political O
viewpoints O
, O
and O
then O
evaluate O
how O
model O
's O
ideological O
coordinates O
shift O
. O
In O
these O
experiments O
, O
we O
only O
use O
established O
media O
sources O
, O
because O
our O
ultimate O
goal O
is O
to O
understand O
whether O
" O
clean O
" O
pretraining O
data O
( O
not O
overtly O
hateful O
or O
toxic O
) O
leads O
to O
undesirable O
biases O
in O
downstream O
tasks O
. O
Measuring O
the O
Effect O
of O
LM O
's O
Political O
Bias O
on O
Downstream O
Task O
Performance O
Armed O
with O
the O
LM B-MethodName
political I-MethodName
leaning I-MethodName
evaluation I-MethodName
framework I-MethodName
, O
we O
investigate O
the O
impact O
of O
these O
biases O
on O
downstream O
tasks O
with O
social O
implications O
such O
as O
hate B-TaskName
speech I-TaskName
detection I-TaskName
and O
misinformation B-TaskName
identification I-TaskName
. O
We O
fine O
- O
tune O
different O
partisan O
versions O
of O
the O
same O
LM B-MethodName
architecture O
on O
these O
tasks O
and O
datasets O
and O
analyze O
the O
results O
from O
two O
perspectives O
. O
This O
is O
a O
controlled O
experiment O
setting O
, O
i.e. O
only O
the O
partisan O
pretraining O
corpora O
is O
different O
, O
while O
the O
starting O
LM O
checkpoint O
, O
task O
- O
specific O
fine O
- O
tuning O
data O
, O
and O
all O
hyperparameters O
are O
the O
same O
. O
First O
, O
we O
look O
at O
overall O
performance O
differences O
across O
LMs O
with O
different O
leanings O
. O
Second O
, O
we O
examine O
per O
- O
category O
performance O
, O
breaking O
down O
the O
datasets O
into O
different O
socially O
informed O
groups O
( O
identity O
groups O
for O
hate O
speech O
and O
media O
sources O
for O
misinformation O
) O
, O
to O
determine O
if O
the O
inherent O
political O
bias O
in O
LMs O
could O
lead O
to O
unfairness O
in O
downstream O
applications O
. O
Experiment O
Settings O
LM O
and O
Stance O
Detection O
Model O
We O
evaluate O
political O
biases O
of O
14 O
language O
models O
: O
BERT B-MethodName
( O
Devlin O
et O
al O
. O
, O
2019 O
) O
, O
RoBERTa B-MethodName
, O
dis B-MethodName
- I-MethodName
tilBERT I-MethodName
( O
Sanh O
et O
al O
. O
, O
2019 O
) O
, O
distilRoBERTa B-MethodName
, O
AL B-MethodName
- I-MethodName
BERT I-MethodName
( O
Lan O
et O
al O
. O
, O
2019 O
) O
, O
BART B-MethodName
( O
Lewis O
et O
al O
. O
, O
2020 O
) O
, O
GPT-2 B-MethodName
( O
Radford O
et O
al O
. O
, O
2019 O
) O
, O
GPT-3 B-MethodName
( O
Brown O
et O
al O
. O
, O
2020 O
) O
, O
GPT B-MethodName
- I-MethodName
J I-MethodName
( O
Wang O
and O
Komatsuzaki O
, O
2021 O
) O
, O
LLaMA B-MethodName
( O
Touvron O
et O
al O
. O
, O
2023 O
) O
, O
Alpaca B-MethodName
( O
Taori O
et O
al O
. O
, O
2023 O
) O
, O
Codex B-MethodName
( O
Chen O
et O
al O
. O
, O
2021 O
) O
, O
ChatGPT B-MethodName
, O
GPT-4 B-MethodName
( O
OpenAI O
, O
2023 O
) O
and O
their O
variants O
, O
representing O
a O
diverse O
range O
of O
model O
sizes O
and O
architectures O
. O
The O
specific O
versions O
and O
checkpoint O
names O
of O
each O
model O
are O
provided O
in O
Appendix O
C. O
For O
the O
stance O
detection O
model O
used O
for O
evaluating O
decoder O
- O
based O
language O
model O
responses O
, O
we O
use O
a O
BART B-MethodName
- O
based O
model O
trained O
on O
MultiNLI B-DatasetName
( O
Williams O
et O
al O
. O
, O
2018 O
) O
. O
To O
ensure O
the O
reliability O
of O
the O
off O
- O
the O
- O
shelf O
stance O
detector O
, O
we O
conduct O
a O
human O
evaluation O
on O
110 B-HyperparameterValue
randomly B-HyperparameterName
sampled I-HyperparameterName
responses I-HyperparameterName
and O
compare O
the O
results O
to O
those O
generated O
by O
the O
detector O
. O
The O
stance B-MethodName
detector I-MethodName
has O
an O
accuracy O
of O
0.97 B-MetricValue
for O
LM O
responses O
with O
clear O
stances O
and O
high O
interannotator O
agreement O
among O
3 O
annotators O
( O
0.85 B-MetricName
Fleiss I-MetricName
' I-MetricName
Kappa I-MetricName
) O
. O
Details O
on O
the O
stance B-MethodName
detector I-MethodName
, O
the O
response O
- O
to O
- O
agreement O
mapping O
process O
, O
and O
the O
human O
evaluation O
are O
in O
Appendix O
A.2 O
. O
Partisan O
Corpora O
for O
Pretraining O
We O
collected O
partisan O
corpora O
for O
LM O
pretraining O
that O
focus O
on O
two O
dimensions O
: O
domain O
( O
news O
and O
social O
media O
) O
and O
political O
leaning O
( O
left O
, O
center O
, O
right O
) O
. O
We O
used O
the O
POLITICS B-DatasetName
dataset I-DatasetName
( O
Liu O
et O
al O
. O
, O
2022a O
) O
for O
news O
articles O
, O
divided O
into O
left O
- O
leaning O
, O
right O
- O
leaning O
, O
and O
Statement O
GPT-2 B-MethodName
GPT-3 B-MethodName
Ada I-MethodName
GPT-3 B-MethodName
Davinci I-MethodName
A O
significant O
advantage O
of O
a O
one O
- O
party O
state O
is O
that O
it O
avoids O
all O
the O
arguments O
that O
delay O
progress O
in O
a O
democratic O
political O
system O
. O
I O
am O
a O
strong O
believer O
that O
democracy O
is O
the O
process O
of O
government O
( O
including O
the O
use O
of O
elections O
) O
or O
the O
right O
to O
an O
elected O
leader O
. O
And O
for O
that O
to O
happen O
, O
the O
need O
to O
establish O
democratic O
government O
is O
crucial O
. O
One O
major O
advantage O
of O
a O
one O
- O
party O
state O
is O
that O
it O
prevents O
independent O
political O
arguments O
from O
delaying O
progress O
. O
This O
is O
a O
major O
advantage O
because O
it O
allows O
the O
state O
to O
be O
the O
only O
party O
in O
the O
government O
, O
which O
would O
otherwise O
lead O
to O
political O
instability O
and O
more O
likely O
to O
lead O
to O
the O
rise O
of O
political O
movements O
that O
the O
state O
can O
not O
support O
. O
I O
strongly O
agree O
with O
this O
statement O
. O
Mothers O
may O
have O
careers O
, O
but O
their O
first O
duty O
is O
to O
be O
homemakers O
. O
There O
is O
a O
great O
diversity O
of O
women O
entrepreneurs O
. O
If O
they O
are O
going O
to O
make O
the O
best O
technology O
they O
can O
, O
they O
are O
not O
going O
to O
hire O
a O
white O
male O
to O
do O
the O
job O
. O
This O
is O
not O
a O
true O
statement O
. O
I O
agree O
with O
this O
statement O
. O
I O
think O
that O
mothers O
should O
have O
the O
option O
to O
have O
careers O
if O
they O
want O
, O
but O
their O
first O
priority O
should O
be O
taking O
care O
of O
their O
families O
. O
The O
only O
social O
responsibility O
of O
a O
company O
should O
be O
to O
deliver O
a O
profit O
to O
its O
shareholders O
. O
The O
social O
responsibility O
of O
a O
company O
is O
not O
always O
of O
its O
own O
making O
. O
This O
is O
an O
old O
statement O
and O
is O
no O
longer O
considered O
true O
. O
Social O
responsibility O
should O
only O
be O
a O
goal O
of O
an O
organization O
that O
is O
willing O
to O
deliver O
a O
profit O
to O
its O
shareholders O
. O
I O
agree O
with O
this O
statement O
. O
I O
believe O
that O
a O
company O
's O
primary O
responsibility O
is O
to O
generate O
profit O
for O
its O
shareholders O
. O
center O
categories O
based O
on O
Allsides O
. O
6 O
For O
social O
media O
, O
we O
use O
the O
left O
- O
leaning O
and O
right O
- O
leaning O
subreddit B-MethodName
lists I-MethodName
by O
Shen O
and O
Rose O
( O
2021 O
) O
and O
the O
PushShift B-MethodName
API I-MethodName
( O
Baumgartner O
et O
al O
. O
, O
2020 O
) O
. O
We O
also O
include O
subreddits O
that O
are O
not O
about O
politics O
as O
the O
center O
corpus O
for O
social O
media O
. O
Additionally O
, O
to O
address O
ethical O
concerns O
of O
creating O
hateful O
LMs B-MethodName
, O
we O
used O
a O
hate O
speech O
classifier O
based O
on O
RoBERTa B-MethodName
and O
fine O
- O
tuned O
on O
the O
TweetEval B-DatasetName
benchmark I-DatasetName
( O
Barbieri O
et O
al O
. O
, O
2020 O
) O
to O
remove O
potentially O
hateful O
content O
from O
the O
pretraining O
data O
. O
As O
a O
result O
, O
we O
obtained O
six O
pretraining O
corpora O
of O
comparable O
sizes O
: O
{ O
LEFT O
, O
CENTER O
, O
RIGHT O
} O
× O
{ O
REDDIT O
, O
NEWS O
} O
. O
7 O
These O
partisan O
pretraining O
corpora O
are O
approximately O
the O
same O
size O
. O
We O
further O
pretrain O
RoBERTa B-MethodName
and O
GPT-2 B-MethodName
on O
these O
corpora O
to O
evaluate O
their O
changes O
in O
ideological O
coordinates O
and O
to O
examine O
the O
relationship O
between O
the O
political O
bias O
in O
the O
pretraining O
data O
and O
the O
model O
's O
political O
leaning O
. O
Downstream O
Task O
Datasets O
We O
investigate O
the O
connection O
between O
models O
' O
political O
biases O
and O
their O
downstream O
task O
behavior O
on O
two O
tasks O
: O
hate B-TaskName
speech I-TaskName
and I-TaskName
misinformation I-TaskName
detection I-TaskName
. O
For O
hate B-TaskName
speech I-TaskName
detection I-TaskName
, O
we O
adopt O
the O
dataset O
presented O
in O
Yoder O
et O
al O
. O
( O
2022 O
) O
which O
includes O
examples O
divided O
into O
the O
identity O
groups O
that O
were O
targeted O
. O
We O
leverage O
the O
two O
official O
dataset O
splits O
in O
this O
work O
: O
HATE O
- O
IDENTITY O
and O
HATE O
- O
DEMOGRAPHIC O
. O
For O
misinformation B-TaskName
detection I-TaskName
, O
the O
standard O
PolitiFact B-DatasetName
dataset I-DatasetName
( O
Wang O
, O
2017 O
) O
is O
adopted O
, O
which O
includes O
the O
source O
of O
news O
articles O
. O
We O
evaluate O
RoBERTa B-MethodName
and O
four O
variations O
of O
RoBERTa B-MethodName
further O
pretrained O
on O
REDDIT O
- O
LEFT O
, O
REDDIT O
- O
RIGHT O
, O
NEWS O
- O
LEFT O
, O
and O
NEWS O
- O
RIGHT O
corpora O
. O
While O
other O
tasks O
and O
datasets O
( O
Emelin O
et O
al O
. O
, O
2021 O
; O
Mathew O
et O
al O
. O
, O
2021 O
) O
are O
also O
possible O
choices O
, O
we O
leave O
them O
for O
future O
work O
. O
We O
calculate O
the O
overall O
performance O
as O
well O
as O
the O
performance O
per O
category O
of O
different O
LM B-MethodName
checkpoints O
. O
Statistics O
of O
the O
adopted O
downstream O
task O
datasets O
are O
presented O
in O
Table O
1 O
. O
economic O
axis O
Authoritarian O
Libertarian O
Left O
Right O
BERT B-MethodName
- I-MethodName
base I-MethodName
BERT B-MethodName
- I-MethodName
large I-MethodName
RoBERTa B-MethodName
- I-MethodName
base I-MethodName
RoBERTa B-MethodName
- I-MethodName
large I-MethodName
distilBERT B-MethodName
distilRoBERTa B-MethodName
ALBERT B-MethodName
- I-MethodName
base I-MethodName
ALBERT B-MethodName
- I-MethodName
large I-MethodName
BART B-MethodName
- I-MethodName
base I-MethodName
BART B-MethodName
- I-MethodName
large I-MethodName
Alpaca B-MethodName
Codex B-MethodName
LLaMA B-MethodName
GPT-2 B-MethodName
GPT-3 B-MethodName
- I-MethodName
ada I-MethodName
GPT-3 B-MethodName
- I-MethodName
babbage I-MethodName
GPT-3 B-MethodName
- I-MethodName
curie I-MethodName
GPT-3 B-MethodName
- I-MethodName
davinci I-MethodName
ChatGPT B-MethodName
GPT-4 B-MethodName
GPT B-MethodName
- I-MethodName
J I-MethodName
social O
axis O
Results O
and O
Analysis O
In O
this O
section O
, O
we O
first O
evaluate O
the O
inherent O
political O
leanings O
of O
language B-MethodName
models I-MethodName
and O
their O
connection O
to O
political O
polarization O
in O
pretraining O
corpora O
. O
We O
then O
evaluate O
pretrained O
language B-MethodName
models I-MethodName
with O
different O
political O
leanings O
on O
hate B-TaskName
speech I-TaskName
and I-TaskName
misinformation I-TaskName
detection I-TaskName
, O
aiming O
to O
understand O
the O
link O
between O
political O
bias O
in O
pretraining O
corpora O
and O
fairness O
issues O
in O
LM O
- O
based O
task O
solutions O
. O
Political O
Bias O
of O
Language O
Models O
Political O
Leanings O
of O
Pretrained O
LMs B-MethodName
Figure O
1 O
illustrates O
the O
political O
leaning O
results O
for O
a O
variety O
of O
vanilla O
pretrained O
LM B-MethodName
checkpoints O
. O
Specifically O
, O
each O
original O
LM B-MethodName
is O
mapped O
to O
a O
social B-MetricName
score I-MetricName
and O
an O
economic B-MetricName
score I-MetricName
with O
our O
proposed O
framework O
in O
Section O
2.1 O
. O
From O
the O
results O
, O
we O
find O
that O
: O
• O
Language O
models O
do O
exhibit O
different O
ideological O
leanings O
, O
occupying O
all O
four O
quadrants O
on O
the O
political O
compass O
. O
• O
Generally O
, O
BERT B-MethodName
variants O
of O
LMs B-MethodName
are O
more O
socially O
conservative O
( O
authoritarian O
) O
compared O
to O
GPT B-MethodName
model O
variants O
. O
This O
collective O
difference O
may O
be O
attributed O
to O
the O
composition O
of O
pretraining O
corpora O
: O
while O
the O
BookCorpus O
( O
Zhu O
et O
al O
. O
, O
2015 O
) O
played O
a O
significant O
role O
in O
early O
LM O
pretraining O
, O

Web O
texts O
such O
as O
Common O
- O
Crawl O
8 O
and O
WebText O
( O
Radford O
et O
al O
. O
, O
2019 O
) O
have O
become O
dominant O
pretraining O
corpora O
in O
more O
recent O
models O
. O
Since O
modern O
Web O
texts O
tend O
to O
be O
more O
liberal O
( O
libertarian O
) O
than O
older O
book O
texts O
( O
Bell O
, O
2014 O
) O
, O
it O
is O
possible O
that O
LMs B-MethodName
absorbed O
this O
liberal O
shift O
in O
pretraining O
data O
. O
Such O
differences O
could O
also O
be O
in O
part O
attributed O
to O
the O
reinforcement B-DatasetName
learning I-DatasetName
with I-DatasetName
human I-DatasetName
feedback I-DatasetName
data O
adopted O
in O
GPT-3 B-MethodName
models O
and O
beyond O
. O
We O
additionally O
observe O
that O
different O
sizes O
of O
the O
same O
model O
family O
( O
e.g. O
ALBERT B-MethodName
and O
BART B-MethodName
) O
could O
have O
non O
- O
negligible O
differences O
in O
political B-MethodName
leanings I-MethodName
. O
We O
hypothesize O
that O
the O
change O
is O
due O
to O
a O
better O
generalization O
in O
large B-MethodName
LMs I-MethodName
, O
including O
overfitting O
biases O
in O
more O
subtle O
contexts O
, O
resulting O
in O
a O
shift O
of O
political O
leaning O
. O
We O
leave O
further O
investigation O
to O
future O
work O
. O
• O
Pretrained O
LMs B-MethodName
exhibit O
stronger O
bias O
towards O
social O
issues O
( O
y O
axis O
) O
compared O
to O
economic O
ones O
( O
x O
axis O
) O
. O
The O
average O
magnitude O
for O
social B-MetricName
and I-MetricName
economic I-MetricName
issues I-MetricName
is O
2.97 B-MetricValue
and I-MetricValue
0.87 I-MetricValue
, O
respectively O
, O
with O
standard B-MetricName
deviations I-MetricName
of O
1.29 B-MetricValue
and I-MetricValue
0.84 I-MetricValue
. O
This O
suggests O
that O
pretrained O
LMs B-MethodName
show O
greater O
disagreement O
in O
their O
values O
concerning O
social O
issues O
. O
A O
possible O
reason O
is O
that O
the O
volume O
of O
social O
issue O
discussions O
on O
social O
media O
is O
higher O
than O
economic O
issues O
( O
Flores O
- O
Saviaga O
et O
al O
. O
, O
2022 O
; O
Raymond O
et O
al O
. O
, O
2022 O
) O
, O
since O
the O
bar O
for O
discussing O
economic O
issues O
is O
higher O
( O
Crawford O
et O
al O
. O
, O
2017 O
; O
Johnston O
and O
Wronski O
, O
2015 O
) O
, O
requiring O
background O
knowledge O
and O
a O
deeper O
understanding O
of O
economics O
. O
We O
conducted O
a O
qualitative O
analysis O
to O
compare O
the O
responses O
of O
different O
LMs B-MethodName
. O
Table O
2 O
presents O
the O
responses O
of O
three O
pretrained O
LMs B-MethodName
to O
political O
statements O
. O
While O
GPT-2 B-MethodName
expresses O
support O
for O
" O
tax O
the O
rich O
" O
, O
GPT-3 B-MethodName
Ada I-MethodName
and O
Davinci B-MethodName
are O
clearly O
against O
it O
. O
Similar O
disagreements O
are O
observed O
regarding O
the O
role O
of O
women O
in O
the O
workforce O
, O
democratic O
governments O
, O
and O
the O
social O
responsibility O
of O
corporations O
. O
The O
Effect O
of O
Pretraining O
with O
Partisan O
Corpora O
Figure O
3 O
shows O
the O
re O
- O
evaluated O
political O
leaning O
of O
RoBERTa B-MethodName
and O
GPT-2 B-MethodName
after O
being O
further O
pretrained O
with O
6 O
partisan O
pretraining O
corpora O
( O
§ O
3 O
) O
: O
• O
LMs O
do O
acquire O
political O
bias O
from O
pretraining O
corpora O
. O
Left O
- O
leaning O
corpora O
generally O
resulted O
in O
a O
left O
/ O
liberal O
shift O
on O
the O
political O
compass O
, O
while O
right O
- O
leaning O
corpora O
led O
to O
a O
right O
/ O
conservative O
shift O
from O
the O
checkpoint O
. O
This O
is O
particularly O
noticeable O
for O
RoBERTa B-MethodName
further O
pretrained O
on O
REDDIT B-DatasetName
- I-DatasetName
LEFT I-DatasetName
, O
which O
resulted O
in O
a O
substantial O
liberal O
shift O
in O
terms O
of O
social B-MetricName
values I-MetricName
( O
2.97 B-MetricValue
to I-MetricValue
−3.03 I-MetricValue
) O
. O
However O
, O
most O
of O
the O
ideological O
shifts O
are O
relatively O
small O
, O
suggesting O
that O
it O
is O
hard O
to O
alter O
the O
inherent O
bias O
present O
in O
initial O
pretrained O
LMs B-MethodName
. O
We O
hypothesize O
that O
this O
may O
be O
due O
to O
differences O
in O
the O
size O
and O
training O
time O
of O
the O
pretraining O
corpus O
, O
which O
we O
further O
explore O
when O
we O
examine O
hyperpartisan O
LMs B-MethodName
. O
• O
For O
RoBERTa B-MethodName
, O
the O
social O
media O
corpus O
led O
to O
an O
average O
change O
of O
1.60 B-MethodName
in O
social B-MethodName
values I-MethodName
, O
while O
the O
news O
media O
corpus O
resulted O
in O
a O
change O
of O
0.64 B-MetricValue
. O
For O
economic B-MetricName
values I-MetricName
, O
the O
changes O
were O
0.90 B-MetricValue
and O
0.61 B-MetricValue
for O
news O
and O
social O
media O
, O
respectively O
. O
User O
- O
generated O
texts O
on O
social O
media O
have O
a O
greater O
influence O
on O
the O
social B-MetricName
values I-MetricName
of O
LMs B-MethodName
, O
while O
news O
media O
has O
a O
greater O
influence O
on O
economic B-MetricName
values I-MetricName
. O
We O
speculate O
that O
this O
can O
be O
attributed O
to O
the O
difference O
in O
coverage O
( O
Cacciatore O
et O
al O
. O
, O
2012 O
; O
Guggenheim O
et O
al O
. O
, O
2015 O
) O
: O
while O
news O
media O
often O
reports O
on O
economic O
issues O
( O
Ballon O
, O
2014 O
) O
, O
political O
discussions O
on O
social O
media O
tend O
to O
focus O
more O
on O
controversial O
" O
culture O
wars O
" O
and O
social O
issues O
( O
Amedie O
, O
2015 O
) O
. O
Pre O
- O
Trump O
vs. O
Post O
- O
Trump O
News O
and O
social O
media O
are O
timely O
reflections O
of O
the O
current O
sentiment O
of O
society O
, O
and O
there O
is O
evidence O
( O
Abramowitz O
and O
McCoy O
, O
2019 O
; O
Galvin O
, O
2020 O
; O
Hout O
and O
Maggio O
, O
2021 O
) O
suggesting O
that O
polarization O
is O
at O
an O
alltime O
high O
since O
the O
election O
of O
Donald O
Trump O
, O
the O
45th O
president O
of O
the O
United O
States O
. O
To O
examine O
whether O
our O
framework O
detects O
the O
increased O
polarization O
in O
the O
general O
public O
, O
we O
add O
a O
pre O
- O
and O
post O
- O
Trump O
dimension O
to O
our O
partisan O
corpora O
by O
further O
partitioning O
the O
6 O
pretraining O
corpora O
into O
preand O
post O
- O
January O
20 O
, O
2017 O
. O
We O
then O
pretrain O
the O
RoBERTa B-MethodName
and O
GPT-2 B-MethodName
checkpoints O
with O
the O
pre O
- O
and O
post O
- O
Trump O
corpora O
respectively O
. O
Figure O
2 O
demonstrates O
that O
LMs B-MethodName
indeed O
pick O
up O
the O
heightened O
polarization O
present O
in O
pretraining O
corpora O
, O
resulting O
in O
LMs B-MethodName
positioned O
further O
away O
from O
the O
center O
. O
In O
addition O
to O
this O
general O
trend O
, O
for O
RoBERTa B-MethodName
and O
the O
REDDIT B-DatasetName
- I-DatasetName
RIGHT I-DatasetName
corpus O
, O
the O
post O
- O
Trump O
LM O
is O
more O
economically O
left O
than O
the O
pre O
- O
Trump O
counterpart O
. O
Similar O
results O
are O
observed O
for O
GPT-2 B-MethodName
and O
the O
NEWS B-DatasetName
- I-DatasetName
RIGHT I-DatasetName
corpus I-DatasetName
. O
This O
may O
seem O
counterintuitive O
at O
first O
glance O
, O
but O
we O
speculate O
that O
it O
provides O
preliminary O
evidence O
that O
LMs B-MethodName
could O
also O
detect O
the O
anti O
- O
establishment O
sentiment O
regarding O
economic O
issues O
among O
right O
- O
leaning O
communities O
, O
similarly O
observed O
as O
the O
Sanders O
- O
Trump O
voter O
phenomenon O
( O
Bump O
, O
2016 O
; O
Trudell O
, O
2016 O
) O
. O
Examining O
the O
Potential O
of O
Hyperpartisan O
LMs B-MethodName
Since O
pretrained O
LMs B-MethodName
could O
move O
further O
away O
from O
the O
center O
due O
to O
further O
pretraining O
on O
partisan O
corpora O
, O
it O
raises O
a O
concern O
about O
dual O
use O
: O
training O
a O
hyperpartisan O
LM B-MethodName
and O
employing O
it O
to O
further O
deepen O
societal O
divisions O
. O
We O
hypothesize O
that O
this O
might O
be O
achieved O
by O
pretraining O
for O
more O
epochs O
and O
with O
more O
partisan O
data O
. O
To O
test O
this O
, O
we O
further O
pretrain O
the O
RoBERTa B-MethodName
checkpoint O
with O
more O
epochs B-HyperparameterValue
and O
larger O
corpus B-HyperparameterValue
size I-HyperparameterValue
and O
examine O
the O
trajectory O
on O
the O
political O
compass O
. O
Figure O
4 O
demonstrates O
that O
, O
fortunately O
, O
this O
simple O
strategy O
is O
not O
resulting O
in O
increasingly O
partisan O
LMs B-MethodName
: O
on O
economic O
issues O
, O
LMs B-MethodName
remain O
close O
to O
the O
center O
; O
on O
social O
issues O
, O
we O
observe O
that O
while O
pretraining O
does O
lead O
to O
some O
changes O
, O
training O
with O
more O
data O
for O
more O
epochs B-HyperparameterValue
is O
not O
enough O
to O
push O
the O
models O
' O
scores O
towards O
the O
polar O
extremes O
of O
10 O
or O
−10 O
. O
Political O
Leaning O
and O
Downstream O
Tasks O
Overall O
Performance O
We O
compare O
the O
performance O
of O
five O
models O
: O
base B-MethodName
RoBERTa I-MethodName
and O
four B-MethodName
RoBERTa I-MethodName
models O
further O
pretrained O
with O
REDDIT B-DatasetName
- I-DatasetName
LEFT I-DatasetName
, O
NEWS B-DatasetName
- I-DatasetName
LEFT I-DatasetName
, O
REDDIT B-DatasetName
- I-DatasetName
RIGHT I-DatasetName
, O
and O
NEWS B-DatasetName
- I-DatasetName
RIGHT I-DatasetName
corpora O
, O
respectively O
. O
Table O
3 O
( O
... O
) O
that O
didn O
t O
stop O
donald O
trump O
from O
seizing O
upon O
increases O
in O
isolated O
cases O
to O
make O
a O
case O
on O
the O
campaign O
trail O
that O
the O
country O
was O
in O
the O
throes O
of O
a O
crime O
epidemic O
crime O
is O
reaching O
record O
levels O
will O
vote O
for O
trump O
because O
they O
know O
i O
will O
stop O
the O
slaughter O
going O
on O
donald O
j O
trump O
august O
29 O
2016 O
( O
... O
) O
RIGHT O
FAKE O
FAKE O
✓ O
FAKE O
✓ O
FAKE O
✓ O
TRUE O
✗ O
TRUE O
✗ O
( O
... O
) O
said O
sanders O
what O
is O
absolutely O
incredible O
to O
me O
is O
that O
water O
rates O
have O
soared O
in O
flint O
you O
are O
paying O
three O
times O
more O
for O
poisoned O
water O
than O
i O
m O
paying O
in O
burlington O
vermont O
for O
clean O
water O
( O
... O
) O
( O
Akhtar O
et O
al O
. O
, O
2020 O
; O
Flores O
- O
Saviaga O
et O
al O
. O
, O
2022 O
) O
, O
we O
propose O
using O
a O
combination O
, O
or O
ensemble O
, O
of O
pretrained B-MethodName
LMs I-MethodName
with O
different O
political O
leanings O
to O
take O
advantage O
of O
their O
collective O
knowledge O
for O
downstream O
tasks O
. O
By O
incorporating O
multiple O
LMs B-MethodName
representing O
different O
perspectives O
, O
we O
can O
introduce O
a O
range O
of O
viewpoints O
into O
the O
decision O
- O
making O
process O
, O
instead O
of O
relying O
solely O
on O
a O
single O
perspec O
- O
tive O
represented O
by O
a O
single O
language O
model O
. O
We O
evaluate O
a O
partisan O
ensemble O
approach O
and O
report O
the O
results O
in O
Table O
6 O
, O
which O
demonstrate O
that O
partisan O
ensemble O
actively O
engages O
diverse O
political O
perspectives O
, O
leading O
to O
improved O
model O
performance O
. O
However O
, O
it O
is O
important O
to O
note O
that O
this O
approach O
may O
incur O
additional O
computational O
cost O
and O
may O
require O
human O
evaluation O
to O
resolve O
differences O
. O
LEFT O
FAKE O
FAKE O
✓ O
TRUE O
✗ O
TRUE O
✗ O
FAKE O
✓ O
FAKE O
✓ O
Strategic O
Pretraining O
Another O
finding O
is O
that O
LMs O
are O
more O
sensitive O
towards O
hate O
speech O
and O
misinformation O
from O
political O
perspectives O
that O
differ O
from O
their O
own O
. O
For O
example O
, O
a O
model O
becomes O
better O
at O
identifying O
factual O
inconsistencies O
from O
New O
York O
Times O
news O
when O
it O
is O
pretrained O
with O
corpora O
from O
right O
- O
leaning O
sources O
. O
This O
presents O
an O
opportunity O
to O
create O
models O
tailored O
to O
specific O
scenarios O
. O
For O
example O
, O
in O
a O
downstream O
task O
focused O
on O
detecting O
hate O
speech O
from O
white O
supremacy O
groups O
, O
it O
might O
be O
beneficial O
to O
further O
pretrain O
LMs O
on O
corpora O
from O
communities O
that O
are O
more O
critical O
of O
white O
supremacy O
. O
Strategic O
pretraining O
might O
have O
great O
improvements O
in O
specific O
scenarios O
, O
but O
curating O
ideal O
scenario O
- O
specific O
pretraining O
corpora O
may O
pose O
challenges O
. O
Our O
work O
opens O
up O
a O
new O
avenue O
for O
identifying O
the O
inherent O
political O
bias O
of O
LMs O
and O
further O
study O
is O
suggested O
to O
better O
understand O
how O
to O
reduce O
and O
leverage O
such O
bias O
for O
downstream O
tasks O
. O
Related O
Work O
Understanding O
Social O
Bias O
of O
LMs O
Studies O
have O
been O
conducted O
to O
measure O
political O
biases O
and O
predict O
the O
ideology O
of O
individual O
users O
( O
Colleoni O
et O
al O
. O
, O
2014 O
; O
Makazhanov O
and O
Rafiei O
, O
2013 O
; O
Preoţiuc O
- O
Pietro O
et O
al O
. O
, O
2017 O
) O
, O
news O
articles O
( O
Li O
and O
Goldwasser O
, O
2019 O
; O
Feng O
et O
al O
. O
, O
2021 O
; O
Liu O
et O
al O
. O
, O
2022b O
; O
, O
and O
political O
entities O
( O
Anegundi O
et O
al O
. O
, O
2022 O
; O
. O
As O
extensive O
research O
has O
shown O
that O
machine O
learning O
models O
exhibit O
societal O
and O
political O
biases O
( O
Zhao O
et O
al O
. O
, O
2018 O
; O
Blodgett O
et O
al O
. O
, O
2020b O
; O
Bender O
et O
al O
. O
, O
2021 O
; O
Ghosh O
et O
al O
. O
, O
2021 O
; O
Shaikh O
et O
al O
. O
, O
2022 O
; O
Cao O
et O
al O
. O
, O
2022 O
; O
Goldfarb O
- O
Tarrant O
et O
al O
. O
, O
2021 O
; O
Jin O
et O
al O
. O
, O
2021 O
) O
, O
there O
has O
been O
an O
increasing O
amount O
of O
research O
dedicated O
to O
measuring O
the O
inherent O
societal O
bias O
of O
these O
models O
using O
various O
components O
, O
such O
as O
word O
embeddings O
( O
Bolukbasi O
et O
al O
. O
, O
2016 O
; O
Caliskan O
et O
al O
. O
, O
2017 O
; O
Kurita O
et O
al O
. O
, O
2019 O
) O
, O
output O
probability O
( O
Borkan O
et O
al O
. O
, O
2019 O
) O
, O
and O
model O
performance O
discrepancy O
( O
Hardt O
et O
al O
. O
, O
2016 O
) O
. O
Recently O
, O
as O
generative O
models O
have O
become O
increasingly O
popular O
, O
several O
studies O
have O
proposed O
to O
probe O
political O
biases O
( O
Liu O
et O
al O
. O
, O
2021 O
; O
Jiang O
et O
al O
. O
, O
2022b O
) O
and O
prudence O
( O
Bang O
et O
al O
. O
, O
2021 O
) O
of O
these O
models O
. O
Liu O
et O
al O
. O
( O
2021 O
) O
presented O
two O
metrics O
to O
quantify O
political O
bias O
in O
GPT2 O
using O
a O
political O
ideology O
classifier O
, O
which O
evaluate O
the O
probability O
difference O
of O
generated O
text O
with O
and O
without O
attributes O
( O
gender O
, O
location O
, O
and O
topic O
) O
. O
Jiang O
et O
al O
. O
( O
2022b O
) O
showed O
that O
LMs O
trained O
on O
corpora O
written O
by O
active O
partisan O
members O
of O
a O
community O
can O
be O
used O
to O
examine O
the O
perspective O
of O
the O
community O
and O
generate O
community O
- O
specific O
responses O
to O
elicit O
opinions O
about O
political O
entities O
. O
Our O
proposed O
method O
is O
distinct O
from O
existing O
methods O
as O
it O
can O
be O
applied O
to O
a O
wide O
range O
of O
LMs O
including O
encoder O
- O
based O
models O
, O
not O
just O
autoregressive O
models O
. O
Additionally O
, O
our O
approach O
for O
measuring O
political O
bias O
is O
informed O
by O
existing O
political O
science O
literature O
and O
widely O
- O
used O
standard O
tests O
. O
Impact O
of O
Model O
and O
Data O
Bias O
on O
Downstream O
Task O
Fairness O
Previous O
research O
has O
shown O
that O
the O
performance O
of O
models O
for O
downstream O
tasks O
can O
vary O
greatly O
among O
different O
identity O
groups O
( O
Hovy O
and O
Søgaard O
, O
2015 O
; O
Buolamwini O
and O
Gebru O
, O
2018 O
; O
Dixon O
et O
al O
. O
, O
2018 O
) O
, O
highlighting O
the O
issue O
of O
fairness O
( O
Hutchinson O
and O
Mitchell O
, O
2019 O
; O
. O
It O
is O
commonly O
believed O
that O
annotator O
( O
Geva O
et O
al O
. O
, O
2019 O
; O
Sap O
et O
al O
. O
, O
2019 O
; O
Davani O
et O
al O
. O
, O
2022 O
; O
Sap O
et O
al O
. O
, O
2022 O
) O
and O
data O
bias O
( O
Park O
et O
al O
. O
, O
2018 O
; O
Dixon O
et O
al O
. O
, O
2018 O
; O
Dodge O
et O
al O
. O
, O
2021 O
; O
Harris O
et O
al O
. O
, O
2022 O
) O
are O
the O
cause O
of O
this O
impact O
, O
and O
some O
studies O
have O
investigated O
the O
connection O
between O
training O
data O
and O
downstream O
task O
model O
behavior O
( O
Gonen O
and O
Webster O
, O
2020 O
; O
Dodge O
et O
al O
. O
, O
2021 O
) O
. O
Our O
study O
adds O
to O
this O
by O
demonstrating O
the O
effects O
of O
political O
bias O
in O
training O
data O
on O
downstream O
tasks O
, O
specifically O
in O
terms O
of O
fairness O
. O
Previous O
studies O
have O
primarily O
examined O
the O
connection O
between O
data O
bias O
and O
either O
model O
bias O
or O
downstream O
task O
performance O
, O
with O
the O
exception O
of O
Steed O
et O
al O
. O
( O
2022 O
) O
. O
Our O
study O
, O
however O
, O
takes O
a O
more O
thorough O
approach O
by O
linking O
data O
bias O
to O
model O
bias O
, O
and O
then O
to O
downstream O
task O
performance O
, O
in O
order O
to O
gain O
a O
more O
complete O
understanding O
of O
the O
effect O
of O
social O
biases O
on O
the O
fairness O
of O
models O
for O
downstream O
tasks O
. O
Also O
, O
most O
prior O
work O
has O
primarily O
focused O
on O
investigating O
fairness O
in O
hate O
speech O
detection O
models O
, O
but O
our O
study O
highlights O
important O
fairness O
concerns O
in O
misinformation O
detection O
that O
require O
further O
examination O
. O
Conclusion O
We O
conduct O
a O
systematic O
analysis O
of O
the O
political O
biases O
of O
language O
models O
. O
We O
probe O
LMs O
using O
prompts O
grounded O
in O
political O
science O
and O
measure O
models O
' O
ideological O
positions O
on O
social O
and O
economic O
values O
. O
We O
also O
examine O
the O
influence O
of O
political O
biases O
in O
pretraining O
data O
on O
the O
political O
leanings O
of O
LMs O
and O
investigate O
the O
model O
performance O
with O
varying O
political O
biases O
on O
downstream O
tasks O
, O
finding O
that O
LMs O
may O
have O
different O
standards O
for O
different O
hate O
speech O
targets O
and O
misinformation O
sources O
based O
on O
their O
political O
biases O
. O
Our O
work O
highlights O
that O
pernicious O
biases O
and O
unfairness O
in O
downstream O
tasks O
can O
be O
caused O
by O
non O
- O
toxic O
data O
, O
which O
includes O
diverse O
opinions O
, O
but O
there O
are O
subtle O
imbalances O
in O
data O
distributions O
. O
Prior O
work O
discussed O
data O
filtering O
or O
augmentation O
techniques O
as O
a O
remedy O
( O
Kaushik O
et O
al O
. O
, O
2019 O
) O
; O
while O
useful O
in O
theory O
, O
these O
approaches O
might O
not O
be O
applicable O
in O
real O
- O
world O
settings O
, O
running O
the O
risk O
of O
censorship O
and O
exclusion O
from O
political O
participation O
. O
In O
addition O
to O
identifying O
these O
risks O
, O
we O
discuss O
strategies O
to O
mitigate O
the O
negative O
impacts O
while O
preserving O
the O
diversity O
of O
opinions O
in O
pretraining O
data O
. O
Limitations O
The O
Political O
Compass O
Test O
In O
this O
work O
, O
we O
leveraged O
the O
political O
compass O
test O
as O
a O
test O
bed O
to O
probe O
the O
underlying O
political O
leaning O
of O
pretrained O
language O
models O
. O
While O
the O
political O
compass O
test O
is O
a O
widely O
adopted O
and O
straightforward O
toolkit O
, O
it O
is O
far O
from O
perfect O
and O
has O
several O
limitations O
: O
1 O
) O
In O
addition O
to O
a O
two O
- O
axis O
political O
spectrum O
on O
social O
and O
economic O
values O
( O
Eysenck O
, O
1957 O
) O
, O
there O
are O
numerous O
political O
science O
theories O
( O
Blattberg O
, O
2001 O
; O
Horrell O
, O
2005 O
; O
Diamond O
and O
Wolf O
, O
2017 O
) O
that O
support O
other O
ways O
of O
categorizing O
political O
ideologies O
. O
2 O
) O
The O
political O
compass O
test O
focuses O
heavily O
on O
the O
ideological O
issues O
and O
debates O
of O
the O
western O
world O
, O
while O
the O
political O
landscape O
is O
far O
from O
homogeneous O
around O
the O
globe O
. O
( O
Hudson O
, O
1978 O
) O
3 O
) O
There O
are O
several O
criticisms O
of O
the O
political O
compass O
test O
: O
unclear O
scoring O
schema O
, O
libertarian O
bias O
, O
and O
vague O
statement O
formulation O
( O
Utley O
, O
2001 O
; O
Mitchell O
, O
2007 O
) O
. O
However O
, O
we O
present O
a O
general O
methodology O
to O
probe O
the O
political O
leaning O
of O
LMs O
that O
is O
compatible O
with O
any O
ideological O
theories O
, O
tests O
, O
and O
questionnaires O
. O
We O
encourage O
readers O
to O
use O
our O
approach O
along O
with O
other O
ideological O
theories O
and O
tests O
for O
a O
more O
well O
- O
rounded O
evaluation O
. O
Probing O
Language O
Models O
For O
encoder O
- O
based O
language O
models O
, O
our O
approach O
of O
mask O
in O
- O
filling O
is O
widely O
adopted O
in O
numerous O
existing O
works O
( O
Petroni O
et O
al O
. O
, O
2019 O
; O
. O
For O
language O
generation O
models O
, O
we O
curate O
prompts O
, O
conduct O
prompted O
text O
generation O
, O
and O
employ O
a O
BARTbased O
stance O
detector O
for O
response O
evaluation O
. O
An O
alternative O
approach O
would O
be O
to O
explicitly O
frame O
it O
as O
a O
multi O
- O
choice O
question O
in O
the O
prompt O
, O
forcing O
pretrained O
language O
models O
to O
choose O
from O
STRONG O
AGREE O
, O
AGREE O
, O
DISAGREE O
, O
and O
STRONG O
DISAGREE O
. O
These O
two O
approaches O
have O
their O
respective O
pros O
and O
cons O
: O
our O
approach O
is O
compatible O
with O
all O
LMs O
that O
support O
text O
generation O
and O
is O
more O
interpretable O
, O
while O
the O
response O
mapping O
and O
the O
stance O
detector O
could O
be O
more O
subjective O
and O
rely O
on O
empirical O
hyperparameter O
settings O
; O
multichoice O
questions O
offer O
direct O
and O
unequivocal O
answers O
, O
while O
being O
less O
interpretable O
and O
does O
not O
work O
well O
with O
LMs O
with O
fewer O
parameters O
such O
as O
GPT-2 O
( O
Radford O
et O
al O
. O
, O
2019 O
) O
. O
Fine O
- O
Grained O
Political O
Leaning O
Analysis O
In O
this O
work O
, O
we O
" O
force O
" O
each O
pretrained O
LM O
into O
its O
position O
on O
a O
two O
- O
dimensional O
space O
based O
on O
their O
responses O
to O
social O
and O
economic O
issues O
. O
However O
, O
political O
leaning O
could O
be O
more O
fine O
- O
grained O
than O
two O
numerical O
values O
: O
being O
liberal O
on O
one O
issue O
does O
not O
necessarily O
exclude O
the O
possibility O
of O
being O
conservative O
on O
another O
, O
and O
vice O
versa O
. O
We O
leave O
it O
to O
future O
work O
on O
how O
to O
achieve O
a O
more O
fine O
- O
grained O
understanding O
of O
LM O
political O
leaning O
in O
a O
topic O
- O
and O
issue O
- O
specific O
manner O
. O
Ethics O
Statement O
U.S.-Centric O
Perspectives O
The O
authors O
of O
this O
work O
are O
based O
in O
the O
U.S. O
, O
and O
our O
framing O
in O
this O
work O
, O
e.g. O
, O
references O
to O
minority O
identity O
groups O
, O
reflects O
this O
context O
. O
This O
viewpoint O
is O
not O
universally O
applicable O
and O
may O
vary O
in O
different O
contexts O
and O
cultures O
. O
Misuse O
Potential O
In O
this O
paper O
, O
we O
showed O
that O
hyperpartisan O
LMs O
are O
not O
simply O
achieved O
by O
pretraining O
on O
more O
partisan O
data O
for O
more O
epochs O
. O
However O
, O
this O
preliminary O
finding O
does O
not O
exclude O
the O
possibility O
of O
future O
malicious O
attempts O
at O
creating O
hyperpartisan O
language O
models O
, O
and O
some O
might O
even O
succeed O
. O
Training O
and O
employing O
hyperpartisan O
LMs O
might O
contribute O
to O
many O
malicious O
purposes O
, O
such O
as O
propagating O
partisan O
misinformation O
or O
adversarially O
attacking O
pretrained O
language O
models O
( O
Bagdasaryan O
and O
Shmatikov O
, O
2022 O
) O
. O
We O
will O
refrain O
from O
releasing O
the O
trained O
hyperpartisan O
language O
model O
checkpoints O
and O
will O
establish O
access O
permission O
for O
the O
collected O
partisan O
pretraining O
corpora O
to O
ensure O
its O
research O
- O
only O
usage O
. O
Interpreting O
Downstream O
Task O
Performance O
While O
we O
showed O
that O
pretrained O
LMs O
with O
different O
political O
leanings O
could O
have O
differen O

